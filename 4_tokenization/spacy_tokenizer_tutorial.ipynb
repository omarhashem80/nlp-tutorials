{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omarhashem80/nlp-tutorials/blob/main/4_tokenization/spacy_tokenizer_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUTwHjBFPWa0"
      },
      "source": [
        "<h2 align=\"center\">Spacy Tokenization Tutorial</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iDKUc8mAPWa3"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGufSiPcPWa4"
      },
      "source": [
        "Create blank language object and tokenize words in a sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "scrolled": true,
        "id": "AdMhZQx6PWa4",
        "outputId": "483eea0e-75f2-4630-9532-e7486e33ab5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dr.\n",
            "Strange\n",
            "loves\n",
            "pav\n",
            "bhaji\n",
            "of\n",
            "mumbai\n",
            "as\n",
            "it\n",
            "costs\n",
            "only\n",
            "2\n",
            "$\n",
            "per\n",
            "plate\n",
            ".\n"
          ]
        }
      ],
      "source": [
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "doc = nlp(\"Dr. Strange loves pav bhaji of mumbai as it costs only 2$ per plate.\")\n",
        "\n",
        "for token in doc:\n",
        "    print(token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySM2tVwaPWa5"
      },
      "source": [
        "Creating blank language object gives a tokenizer and an empty pipeline. We will look more into language pipelines in next tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQFsdgeRPWa5"
      },
      "source": [
        "<img src=\"https://github.com/omarhashem80/nlp-tutorials/blob/main/4_tokenization/spacy_blank_pipeline.jpg?raw=1\" height=100, width=500/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waSWpkyEPWa6"
      },
      "source": [
        "<h3>Using index to grab tokens</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3Gm7km14PWa6",
        "outputId": "69eba6eb-a3f2-4ebe-c57b-0f91710b05c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dr."
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "doc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "scrolled": true,
        "id": "yo7R8bpkPWa6",
        "outputId": "dafa4d49-fcb9-4da5-a7bf-0ed937a9d7a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Strange'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "token = doc[1]\n",
        "token.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "scrolled": false,
        "id": "tmZ_INmAPWa7",
        "outputId": "c4ed0247-a63c-420b-8211-30b821b7d0a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_',\n",
              " '__bytes__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__pyx_vtable__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__unicode__',\n",
              " 'ancestors',\n",
              " 'check_flag',\n",
              " 'children',\n",
              " 'cluster',\n",
              " 'conjuncts',\n",
              " 'dep',\n",
              " 'dep_',\n",
              " 'doc',\n",
              " 'ent_id',\n",
              " 'ent_id_',\n",
              " 'ent_iob',\n",
              " 'ent_iob_',\n",
              " 'ent_kb_id',\n",
              " 'ent_kb_id_',\n",
              " 'ent_type',\n",
              " 'ent_type_',\n",
              " 'get_extension',\n",
              " 'has_dep',\n",
              " 'has_extension',\n",
              " 'has_head',\n",
              " 'has_morph',\n",
              " 'has_vector',\n",
              " 'head',\n",
              " 'i',\n",
              " 'idx',\n",
              " 'iob_strings',\n",
              " 'is_alpha',\n",
              " 'is_ancestor',\n",
              " 'is_ascii',\n",
              " 'is_bracket',\n",
              " 'is_currency',\n",
              " 'is_digit',\n",
              " 'is_left_punct',\n",
              " 'is_lower',\n",
              " 'is_oov',\n",
              " 'is_punct',\n",
              " 'is_quote',\n",
              " 'is_right_punct',\n",
              " 'is_sent_end',\n",
              " 'is_sent_start',\n",
              " 'is_space',\n",
              " 'is_stop',\n",
              " 'is_title',\n",
              " 'is_upper',\n",
              " 'lang',\n",
              " 'lang_',\n",
              " 'left_edge',\n",
              " 'lefts',\n",
              " 'lemma',\n",
              " 'lemma_',\n",
              " 'lex',\n",
              " 'lex_id',\n",
              " 'like_email',\n",
              " 'like_num',\n",
              " 'like_url',\n",
              " 'lower',\n",
              " 'lower_',\n",
              " 'morph',\n",
              " 'n_lefts',\n",
              " 'n_rights',\n",
              " 'nbor',\n",
              " 'norm',\n",
              " 'norm_',\n",
              " 'orth',\n",
              " 'orth_',\n",
              " 'pos',\n",
              " 'pos_',\n",
              " 'prefix',\n",
              " 'prefix_',\n",
              " 'prob',\n",
              " 'rank',\n",
              " 'remove_extension',\n",
              " 'right_edge',\n",
              " 'rights',\n",
              " 'sent',\n",
              " 'sent_start',\n",
              " 'sentiment',\n",
              " 'set_extension',\n",
              " 'set_morph',\n",
              " 'shape',\n",
              " 'shape_',\n",
              " 'similarity',\n",
              " 'subtree',\n",
              " 'suffix',\n",
              " 'suffix_',\n",
              " 'tag',\n",
              " 'tag_',\n",
              " 'tensor',\n",
              " 'text',\n",
              " 'text_with_ws',\n",
              " 'vector',\n",
              " 'vector_norm',\n",
              " 'vocab',\n",
              " 'whitespace_']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "dir(token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jHxr9LRBPWa7",
        "outputId": "2446d48e-44b7-42fc-aa15-46258c40aa55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.lang.en.English"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>spacy.lang.en.English</b><br/>def __call__(text: Union[str, Doc], *, disable: Iterable[str]=SimpleFrozenList(), component_cfg: Optional[Dict[str, Dict[str, Any]]]=None) -&gt; Doc</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/spacy/lang/en/__init__.py</a>A text-processing pipeline. Usually you&#x27;ll load this once per process,\n",
              "and pass the instance around your application.\n",
              "\n",
              "Defaults (class): Settings, data and factory methods for creating the `nlp`\n",
              "    object and processing pipeline.\n",
              "lang (str): IETF language code, such as &#x27;en&#x27;.\n",
              "\n",
              "DOCS: https://spacy.io/api/language</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 22);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "type(nlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1-T0YDPpPWa7",
        "outputId": "be36c8c5-96a0-404c-d718-14eb9452f565",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.doc.Doc"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "type(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1Qo5prC1PWa7",
        "outputId": "43466394-0689-4223-d1a7-fde1bf20dc9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.token.Token"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "type(token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "scrolled": true,
        "id": "YAQj4jE_PWa7",
        "outputId": "9feb46c6-c0ff-4d3d-de50-404fd81f3a31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "nlp.pipe_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bI4U3IqPWa8"
      },
      "source": [
        "<h3>Span object</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "aLa2h4MhPWa8",
        "outputId": "6265470e-d2ee-4d96-b4fd-e82741156349",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dr. Strange loves pav bhaji"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "span = doc[0:5]\n",
        "span"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tHo--HytPWa8",
        "outputId": "034629c5-73d5-438a-fa89-5ca9a5f1bc66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.span.Span"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "type(span)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcxfS50iPWa8"
      },
      "source": [
        "<h3>Token attributes</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3QfHPkMnPWa8"
      },
      "outputs": [],
      "source": [
        "doc = nlp(\"Tony gave two $ to Peter.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yC2Aa7-pPWa8",
        "outputId": "44bf8e22-83af-44af-e5e7-322e4ffbc6bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tony"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "token0 = doc[0]\n",
        "token0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QvumcbxiPWa9",
        "outputId": "8cd9b75a-bd04-45f8-acee-483d023c9f28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "token0.is_alpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "scrolled": true,
        "id": "RxoRsLCEPWa9",
        "outputId": "0d2b0487-1d68-45ca-f7d5-dc5b95c0856c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "token0.like_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Wh7AUVx8PWa9",
        "outputId": "2eb33ca1-6ff3-4633-a190-2f5821f31902",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "two"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "token2 = doc[2]\n",
        "token2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ueW7tN2XPWa9",
        "outputId": "684a20f6-af46-4dd2-b48e-2ad4d72946dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "token2.like_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "uDFmBoLVPWa9",
        "outputId": "6856512c-0550-43a1-b3b8-de78ff6ffb61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "$"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "token3 = doc[3]\n",
        "token3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "D435cjU9PWa9",
        "outputId": "5b755588-d082-44a0-aca0-8b48134cdf0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "token3.like_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0MNSoLTTPWa9",
        "outputId": "fa6f27c5-444a-4ac4-f60e-f3e5921b6bdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "token3.is_currency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "scrolled": true,
        "id": "tp8yMPS6PWa9",
        "outputId": "1c8616c3-84af-447e-fcfe-a55654dae887",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tony ==> index:  0 is_alpha: True is_punct: False like_num: False is_currency: False\n",
            "gave ==> index:  1 is_alpha: True is_punct: False like_num: False is_currency: False\n",
            "two ==> index:  2 is_alpha: True is_punct: False like_num: True is_currency: False\n",
            "$ ==> index:  3 is_alpha: False is_punct: False like_num: False is_currency: True\n",
            "to ==> index:  4 is_alpha: True is_punct: False like_num: False is_currency: False\n",
            "Peter ==> index:  5 is_alpha: True is_punct: False like_num: False is_currency: False\n",
            ". ==> index:  6 is_alpha: False is_punct: True like_num: False is_currency: False\n"
          ]
        }
      ],
      "source": [
        "for token in doc:\n",
        "    print(token, \"==>\", \"index: \", token.i, \"is_alpha:\", token.is_alpha,\n",
        "          \"is_punct:\", token.is_punct,\n",
        "          \"like_num:\", token.like_num,\n",
        "          \"is_currency:\", token.is_currency,\n",
        "         )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-BUJfWMPWa-"
      },
      "source": [
        "<h3>Collecting email ids of students from students information sheet</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "FBOXPxRcPWa-",
        "outputId": "73b46563-b8fb-4b94-9c6e-2a7a2c81f198",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'students.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-85800d4dd2e6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"students.txt\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'students.txt'"
          ]
        }
      ],
      "source": [
        "with open(\"students.txt\") as f:\n",
        "    text = f.readlines()\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wz-CBpEyPWa-"
      },
      "outputs": [],
      "source": [
        "text = \" \".join(text)\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MC-pKZqPWa-"
      },
      "outputs": [],
      "source": [
        "doc = nlp(text)\n",
        "emails = []\n",
        "for token in doc:\n",
        "    if token.like_email:\n",
        "        emails.append(token.text)\n",
        "emails"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYCMgN4bPWa-"
      },
      "source": [
        "<h3>Support in other languages</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMHFBG4APWa-"
      },
      "source": [
        "Spacy support many language models. Some of them do not support pipelines though!\n",
        "https://spacy.io/usage/models#languages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "COkol3Y5PWa-"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.blank(\"hi\")\n",
        "doc = nlp(\"भैया जी! 5000 ₹ उधार थे वो वापस देदो\")\n",
        "for token in doc:\n",
        "    print(token, token.is_currency)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXccOrvdPWa_"
      },
      "source": [
        "<h3>Customizing tokenizer</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ik39whTgPWa_"
      },
      "outputs": [],
      "source": [
        "from spacy.symbols import ORTH\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "doc = nlp(\"gimme double cheese extra large healthy pizza\")\n",
        "tokens = [token.text for token in doc]\n",
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Rk0njXp0PWa_"
      },
      "outputs": [],
      "source": [
        "nlp.tokenizer.add_special_case(\"gimme\", [\n",
        "    {ORTH: \"gim\"},\n",
        "    {ORTH: \"me\"},\n",
        "])\n",
        "doc = nlp(\"gimme double cheese extra large healthy pizza\")\n",
        "tokens = [token.text for token in doc]\n",
        "tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWMy3DoNPWa_"
      },
      "source": [
        "<h3>Sentence Tokenization or Segmentation</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cds8m4skPWbD"
      },
      "outputs": [],
      "source": [
        "doc = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")\n",
        "for sentence in doc.sents:\n",
        "    print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tT2pHabdPWbD"
      },
      "outputs": [],
      "source": [
        "nlp.pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbr0Z4qxPWbD"
      },
      "outputs": [],
      "source": [
        "nlp.add_pipe('sentencizer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEz1x87mPWbD"
      },
      "outputs": [],
      "source": [
        "doc = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")\n",
        "for sentence in doc.sents:\n",
        "    print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmjsiQ93PWbD"
      },
      "outputs": [],
      "source": [
        "nlp.pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W5Ll8e1PWbE"
      },
      "source": [
        "<h3>Exercise</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX-ESFLpPWbE"
      },
      "source": [
        "(1) Think stats is a free book to study statistics (https://greenteapress.com/thinkstats2/thinkstats2.pdf)\n",
        "\n",
        "This book has references to many websites from where you can download free datasets. You are an NLP engineer working for some company and you want to collect all dataset websites from this book. To keep exercise simple you are given a paragraph from this book and you want to grab all urls from this paragraph using spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "QtybwVODPWbE",
        "outputId": "f1609e8b-bf43-46b1-aaa7-7e89c024d247",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['http://www.data.gov/',\n",
              " 'http://www.science',\n",
              " 'http://data.gov.uk/.',\n",
              " 'http://www3.norc.org/gss+website/',\n",
              " 'http://www.europeansocialsurvey.org/.']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "text='''\n",
        "Look for data to help you address the question. Governments are good\n",
        "sources because data from public research is often freely available. Good\n",
        "places to start include http://www.data.gov/, and http://www.science.\n",
        "gov/, and in the United Kingdom, http://data.gov.uk/.\n",
        "Two of my favorite data sets are the General Social Survey at http://www3.norc.org/gss+website/,\n",
        "and the European Social Survey at http://www.europeansocialsurvey.org/.\n",
        "'''\n",
        "\n",
        "# TODO: Write code here\n",
        "nlp = spacy.blank(\"en\")\n",
        "doc = nlp(text)\n",
        "urls = []\n",
        "for token in doc:\n",
        "    if token.like_url:\n",
        "        urls.append(token.text)\n",
        "urls\n",
        "# Hint: token has an attribute that can be used to detect a url"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Z9O8EGaPWbE"
      },
      "source": [
        "(2) Extract all money transaction from below sentence along with currency. Output should be,\n",
        "\n",
        "two $\n",
        "\n",
        "500 €"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "aeJaHEU0PWbE",
        "outputId": "e6bcfeb5-40a5-4481-e1fa-f7cc26ce1f93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "two $\n",
            "500 €\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['$', '€']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "transactions = \"Tony gave two $ to Peter, Bruce gave 500 € to Steve\"\n",
        "\n",
        "# TODO: Write code here\n",
        "nlp = spacy.blank(\"en\")\n",
        "doc = nlp(transactions)\n",
        "currencies = []\n",
        "for token in doc:\n",
        "    if token.like_num and doc[token.i+1].is_currency:\n",
        "        print(token.text, doc[token.i+1].text)\n",
        "        currencies.append(doc[token.i+1].text)\n",
        "currencies\n",
        "# Hint: Use token.i for the index of a token and token.is_currency for currency symbol detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGljAyV-PWbE"
      },
      "source": [
        "[Click me to see a solution](https://github.com/codebasics/nlp-tutorials/blob/main/4_tokenization/spacy_tokenizer_exercise_solution.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fcWD4VlPWbE"
      },
      "source": [
        "<h3>Further Reading</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxglqp--PWbE"
      },
      "source": [
        "https://spacy.io/usage/linguistic-features#tokenization"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}